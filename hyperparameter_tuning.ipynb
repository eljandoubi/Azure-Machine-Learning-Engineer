{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive\n",
        "\n",
        "Import Dependencies. In the cell below, import all the dependencies that I will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, ScriptRunConfig, Environment\n",
        "\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy,\\\n",
        "                                     choice, randint, PrimaryMetricGoal, HyperDriveConfig\n",
        "\n",
        "\n",
        "from azureml.widgets import RunDetails"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708163844143
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "Get data. In the cell below, I write code to access the data I will be using in this project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config(path=\"/\")\n",
        "\n",
        "experiment_name = 'HyperTune'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708163844531
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "found = False\n",
        "key = \"Employee Attrition\"\n",
        "description_text = \"IBM HR Analytics Employee Attrition & Performance\"\n",
        "\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        dataset = ws.datasets[key] \n",
        "\n",
        "if not found:\n",
        "        url = \"https://raw.githubusercontent.com/eljandoubi/Azure-Machine-Learning-Engineer/main/attrition-dataset.csv\"\n",
        "        dataset = Dataset.Tabular.from_delimited_files(url)        \n",
        "        dataset = dataset.register(workspace=ws,\n",
        "                                   name=key,description=description_text)\n",
        "\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708163848165
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_name = \"automl-vs-hpyer\"\n",
        "\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target, using it!')\n",
        "    \n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target!')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',min_nodes=1, max_nodes=8)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "    \n",
        "cpu_cluster.wait_for_completion(show_output=True)\n",
        " \n",
        "cpu_cluster.get_status().serialize()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708163848383
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration\n",
        "\n",
        "Here I will set configuration for different parameters for our hyperdrive run.\n",
        "\n",
        "I will use `RandomParameterSampling` as the Sampling method, `BanditPolicy` as the Termination policy, and `SKLearn estimator` with the Primary metric as `AUC_weighted`."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598531923519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = Environment(name='hyper_env')\n",
        "\n",
        "# Specify Python dependencies\n",
        "env.python.conda_dependencies.add_pip_package('pandas')\n",
        "env.python.conda_dependencies.add_pip_package('scikit-learn')\n",
        "\n",
        "# Register the environment in your workspace\n",
        "env.register(workspace=ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708163848665
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an early termination policy.\n",
        "early_termination_policy = BanditPolicy(slack_factor=0.1,evaluation_interval=3)\n",
        "\n",
        "#Creating the different params that will be used during training\n",
        "param_sampling = RandomParameterSampling({\"--criterion\": choice(\"gini\", \"entropy\"),\n",
        "                                          \"--bootstrap\": choice(\"True\", \"False\"), \n",
        "                                          \"--max_depth\": randint(10)})\n",
        "\n",
        "#Creating estimator and hyperdrive config\n",
        "src = ScriptRunConfig(source_directory=\".\", script=\"train.py\",\n",
        "                            compute_target=cpu_cluster,environment=env)\n",
        "\n",
        "hyperdrive_run_config = HyperDriveConfig(hyperparameter_sampling=param_sampling,\n",
        "                                         policy=early_termination_policy, \n",
        "                                         primary_metric_name=\"AUC_weighted\", \n",
        "                                         primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                                         max_total_runs=8, \n",
        "                                         max_concurrent_runs=2, \n",
        "                                         run_config=src)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708163848760
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708163851236
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "In the cell below, I use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708164938154
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(hyperdrive_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708164938229
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "In the cell below, I get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        " \n",
        "print('Best Run Id: ', best_run.id)\n",
        "print('AUC_weighted of Best Run is:', best_run_metrics['AUC_weighted'])\n",
        "print('Parameter Values are:',best_run.get_details()['runDefinition']['arguments'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708164938238
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = best_run.register_model(model_name='hyperdrive-model', \n",
        "                                model_path='outputs/model.joblib', \n",
        "                                tags={'Method':'Hyperdrive'}, \n",
        "                                properties={'AUC_weighted': best_run_metrics['AUC_weighted']})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1708164938246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}